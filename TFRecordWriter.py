from __future__ import print_function

import tensorflow as tf

class TFRecordWriter:
    def _int64Feature(self, value):
        """This method takes value that must be a single integer and returns its corresponding
        feature proto message."""
        return tf.train.Feature(int64_list = tf.train.Int64List(value = value if type(value) == list else [value]))

    def _bytesFeature(self, value):
        """This method takes value that must a single byte codes and returns its corresponding
        feature message. Note, each element of the input list is a series of bytes and not only one singel byte."""
        return tf.train.Feature(bytes_list = tf.train.BytesList(value = value if type(value) == list else [value]))

    def _floatFeature(self, value):
        """This method takes value that must be a single float number and returns its corresponding
        feature proto message."""
        return tf.train.Feature(float_list = tf.train.FloatList(value = value if type(value) == list else [value]))

    def _int64FeatureList(self, values):
        """This method takes an input that must be a list of integers and returns its corresponding
        feature proto message."""
        return tf.train.FeatureList(feature = [self._int64Feature(v) for v in values])

    def _bytesFeatureList(self, values):
        """This method takes an input that must be a list bytecodes and returns its corresponding
        feature proto message."""
        return tf.train.FeatureList(feature = [self._bytesFeature(v) for v in values])

    def _floatFeatureList(self, values):
        """This method takes an input that must be a list float numbers and returns its corresponding
        feature proto message."""
        return tf.train.FeatureList(feature = [self._floatFeature(v) for v in values])

    def _scalar2scalar(self, (x, y), xLabel = "input", yLabel = "output", xMessage = None, yMessage = None):
        """This method takes a tuple where the first element is the input of the trainig algorithm. For example, it could by the
        bytecode corresponding to a numpy array image generated by tostring method of numpy array. However, it cannot be a sequence.
        For example, it cannot be a list of integers. y is the true label that the algorithm is trying to predict. Again, y cannot be 
        a sequence. It generates an object of tf.train.Example. Also, it takes a label tuple that denotes
        the feature names for the first and the second elements of the input tuple. xMessagase and yMessage are functions that 
        return the feature messaga protos respectively for the first and second elements of tuple. These functions must return
        tf.train.Feature."""
        if not xMessage:
            xMessage = self._int64Feature
        if not yMessage:
            yMessage = self._int64Feature
        return tf.train.Example(features = tf.train.Features(feature = {xLabel: xMessage(x), yLabel: yMessage(y)}))
        
    def _seq2seq(self, (x, y), xLabel = "input", yLabel = "output", xMessage = None, yMessage = None):
        """This method takes a tuple where the first element is the input of the trainig algorithm which must be a list.
        y, the second element of the input tuple, must ba a python list as well. One application of this method could be machine 
        translation that maps the sequence of takens in the source language to the sequence of the tokens in the target language.
        It generates an object of tf.train.SequenceExample. Also, it takes a label tuple that denotes
        the feature names for the first and the second elements of the input tuple. xMessagase and yMessage are functions that 
        return the feature messaga protos respectively for the first and second elements of tuple. These functions must return
        tf.train.FeatureList."""
        if not xMessage:
            xMessage = self._int64FeatureList
        if not yMessage:
            yMessage = self._int64FeatureList
        return tf.train.SequenceExample(feature_lists = tf.train.FeatureLists(feature_list = {xLabel: xMessage(x), yLabel: yMessage(y)}))

    def _seq2seqContext(self, (cX, cY, x, y), (cXLabel, cYLabel, xLabel, yLabel) = ("vocabSizeSource", "vocabSizeTarget", "source", "target"),
                        cXMessage = None, cYMessage = None, xMessage = None, yMessage = None):
        """This method takes a tuple where the third element is the input of the trainig algorithm which must be a list.
        y, the forth element of the input tuple, must ba a python list as well. The first two element refers to a scalar regarding the 
        training example. One application of this method could be machine translation that maps the sequence of tokens, x, in the source 
        language to the sequence of the tokens, y, in the target language. 
        It generates an object of tf.train.SequenceExample. xMessagase and yMessage are functions that return the feature messages protos 
        respectively for the third and forth elements of tuple. These functions must return tf.train.FeatureList. However, both cXMessage 
        and cYMessage must return tf.train.Feature"""
        if not cXMessage:
            cXMessage = self._int64Feature
        if not cYMessage:
            cYMessage = self._int64Feature
        if not xMessage:
            xMessage = self._int64FeatureList
        if not yMessage:
            yMessage = self._int64FeatureList
        return tf.train.SequenceExample(context = tf.train.Features(feature = {cXLabel: cXMessage(cX), cYLabel: cYMessage(cY)}),
                                        feature_lists = tf.train.FeatureLists(feature_list = {xLabel: xMessage(x), yLabel: yMessage(y)}))
    
    def _scalar2seq(self, (x, y), xLabel = "input", yLabel = "output", xMessage = None, yMessage = None):
        """This method takes a tuple where the first element is the input of the trainig algorithm which must be a scalar.
        y, the second element of the input tuple, must ba a python list. One application of this method could be image 
        captioning that maps a given image to sequence of takens.
        It generates an object of tf.train.SequenceExample. Also, it takes a label tuple that denotes
        the feature names for the first and the second elements of the input tuple. xMessagase and yMessage are functions that 
        return the feature messaga protos respectively for the first and second elements of tuple. yMessage must return
        tf.train.FeatureList and xMessage must return a tf.train.Feature"""
        if not xMessage:
            xMessage = self._bytesFeature
        if not yMessage:
            yMessage = self._int64FeatureList
        return tf.train.SequenceExample(context = tf.train.Features(feature = {xLabel: xMessage(x)}), feature_lists = tf.train.FeatureLists(feature_list = {yLabel: yMessage(y)}))
    
    def seqseq2TFRecord(self, examples, encoder, filename, xLabel = "input", yLabel = "output",
                          xMessage = None, yMessage = None):
        """This method creates and stores TFRecord under filename for the given input examples where examples 
        is a list of tuples where the first element refers to the input of training algorithm and the second element
        refers to the label that the algorithm is trying to predict.
        The encoder could be all the encoder methods that accept tuples with 2 elements: _scalar2scalar, _scalar2seq, 
        _scalar2scalar, _seq2seq"""
        labels = (xLabel, yLabel)
        with tf.python_io.TFRecordWriter(filename) as writer:
            for e in examples:
                writer.write(encoder(e, xLabel = xLabel, yLabel = yLabel, xMessage = xMessage, yMessage = yMessage).SerializeToString())

    def machineTranslation2TFRecord(self, examples, sourceStart, sourceEnd, sourceUnknown, sourceVocabSize, targetStart, targetEnd,
                                    targetUnknown, targetVocabSize, filename):
        """This method creates and stores TFRecord under filename for the given input examples where examples 
        is a list of tuples where the first element refers to the source sequence and the second element is the
        target sequence. The first sequence example written in the file will be a header of the file that will contain
        all the different aspects of the vocab. The examples starting from the second example will be the actual training
        examples."""
        with tf.python_io.TFRecordWriter(filename) as writer:
            sequenceExample = tf.train.SequenceExample(
                context = tf.train.Features(feature = {"sourceStart": self._int64Feature(sourceStart),
                                                       "sourceEnd": self._int64Feature(sourceEnd),
                                                       "sourceUnknown": self._int64Feature(sourceUnknown),
                                                       "sourceVocabSize": self._int64Feature(sourceVocabSize),
                                                       "targetStart": self._int64Feature(targetStart),
                                                       "targetEnd": self._int64Feature(targetEnd),
                                                       "targetUnknown": self._int64Feature(targetUnknown),
                                                       "targetVocabSize": self._int64Feature(targetVocabSize)}))
            writer.write(sequenceExample.SerializeToString())
            for e in examples:
                sequenceExample = tf.train.SequenceExample(
                    feature_lists = tf.train.FeatureLists(feature_list = {
                        "source": self._int64FeatureList(e[0]),
                        "target": self._int64FeatureList(e[1])}))
                writer.write(sequenceExample.SerializeToString())


    @staticmethod
    def iwslt15():
        from Tokens2Indices import Tokens2Indices
        examples, (sourceStart, sourceEnd, sourceUnknown, sourceVocabSize), (
            targetStart, targetEnd, targetUnknown, targetVocabSize) = Tokens2Indices.iwslt15Train(start = "<START>", end = "<END>",
                                                                                                  unknown = "<UNKNOWN>")
        writer = TFRecordWriter()
        writer.machineTranslation2TFRecord(examples = examples, filename = "iwslt15Train.tfrecord", sourceStart = sourceStart,
                                           sourceEnd = sourceEnd, sourceUnknown = sourceUnknown, sourceVocabSize = sourceVocabSize,
                                           targetStart = targetStart, targetEnd = targetEnd,
                                           targetUnknown = targetUnknown, targetVocabSize = targetVocabSize)

        examples, (sourceStart, sourceEnd, sourceUnknown, sourceVocabSize), (
            targetStart, targetEnd, targetUnknown, targetVocabSize) = Tokens2Indices.iwslt15Test(start = "<START>", end = "<END>",
                                                                                                  unknown = "<UNKNOWN>")
        writer = TFRecordWriter()
        writer.machineTranslation2TFRecord(examples = examples, filename = "iwslt15Test.tfrecord", sourceStart = sourceStart,
                                           sourceEnd = sourceEnd, sourceUnknown = sourceUnknown, sourceVocabSize = sourceVocabSize,
                                           targetStart = targetStart, targetEnd = targetEnd,
                                           targetUnknown = targetUnknown, targetVocabSize = targetVocabSize)

def test1():
    examples = [(1, 1), (2, 2), (3, 3)]
    MapTFRecord().genTFRecord(examples, filename = "test.tfrecord")

if __name__ == "__main__":
    #TFRecordWriter.iwslt15()
    TFRecordWriter.segmentation()
                                
                                
